{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Recommendation using Embeddings and Nearest Neighbor Search\n", "\n", "This notebook is **Google Colab ready** and implements a content-based recommender system using OpenAI embeddings."]}, {"cell_type": "code", "metadata": {}, "source": ["!pip install --upgrade openai pandas numpy scikit-learn tqdm"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Set OpenAI API Key"]}, {"cell_type": "code", "metadata": {}, "source": ["import os\n", "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Imports and Configuration"]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd\n", "import numpy as np\n", "import pickle\n", "from tqdm import tqdm\n", "from sklearn.metrics.pairwise import cosine_similarity\n", "from openai import OpenAI\n", "\n", "client = OpenAI()\n", "EMBEDDING_MODEL = \"text-embedding-3-small\"\n", "CACHE_PATH = \"embedding_cache.pkl\""], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Dataset (Upload AG_news_samples.csv)"]}, {"cell_type": "code", "metadata": {}, "source": ["df = pd.read_csv(\"AG_news_samples.csv\")\n", "df.head()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load or Initialize Embedding Cache"]}, {"cell_type": "code", "metadata": {}, "source": ["try:\n", "    with open(CACHE_PATH, \"rb\") as f:\n", "        embedding_cache = pickle.load(f)\n", "except FileNotFoundError:\n", "    embedding_cache = {}"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Embedding Function"]}, {"cell_type": "code", "metadata": {}, "source": ["def get_embedding(text, model=EMBEDDING_MODEL):\n", "    if (text, model) not in embedding_cache:\n", "        response = client.embeddings.create(\n", "            model=model,\n", "            input=text\n", "        )\n", "        embedding_cache[(text, model)] = response.data[0].embedding\n", "        with open(CACHE_PATH, \"wb\") as f:\n", "            pickle.dump(embedding_cache, f)\n", "    return embedding_cache[(text, model)]"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Generate Embeddings"]}, {"cell_type": "code", "metadata": {}, "source": ["descriptions = df[\"description\"].tolist()\n", "embeddings = []\n", "for text in tqdm(descriptions):\n", "    embeddings.append(get_embedding(text))\n", "embeddings = np.array(embeddings)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Recommendation Function"]}, {"cell_type": "code", "metadata": {}, "source": ["def recommend(index, k=5):\n", "    query = embeddings[index].reshape(1, -1)\n", "    scores = cosine_similarity(query, embeddings)[0]\n", "    ranked = scores.argsort()[::-1]\n", "    print(\"SOURCE ARTICLE:\\n\")\n", "    print(descriptions[index])\n", "    print(\"\\n----------------------------\\n\")\n", "    count = 0\n", "    for i in ranked:\n", "        if i == index:\n", "            continue\n", "        count += 1\n", "        print(f\"Recommendation #{count}\")\n", "        print(descriptions[i])\n", "        print(f\"Similarity: {scores[i]:.3f}\\n\")\n", "        if count >= k:\n", "            break"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Test Examples"]}, {"cell_type": "code", "metadata": {}, "source": ["recommend(index=0, k=5)\n", "recommend(index=1, k=5)"], "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}