{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation using Embeddings and Nearest Neighbor Search\n",
    "\n",
    "This notebook is **Google Colab ready** and implements a content-based recommender system using OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai pandas numpy scikit-learn tqdm gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "CACHE_PATH = \"embedding_cache.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset (Upload AG_news_samples.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AG_news_samples.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or Initialize Embedding Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(CACHE_PATH, \"rb\") as f:\n",
    "        embedding_cache = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=EMBEDDING_MODEL):\n",
    "    if (text, model) not in embedding_cache:\n",
    "        response = client.embeddings.create(\n",
    "            model=model,\n",
    "            input=text\n",
    "        )\n",
    "        embedding_cache[(text, model)] = response.data[0].embedding\n",
    "        with open(CACHE_PATH, \"wb\") as f:\n",
    "            pickle.dump(embedding_cache, f)\n",
    "    return embedding_cache[(text, model)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = df[\"description\"].tolist()\n",
    "embeddings = []\n",
    "for text in tqdm(descriptions):\n",
    "    embeddings.append(get_embedding(text))\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(index, k=5):\n",
    "    query = embeddings[index].reshape(1, -1)\n",
    "    scores = cosine_similarity(query, embeddings)[0]\n",
    "    ranked = scores.argsort()[::-1]\n",
    "    print(\"SOURCE ARTICLE:\\n\")\n",
    "    print(descriptions[index])\n",
    "    print(\"\\n----------------------------\\n\")\n",
    "    count = 0\n",
    "    for i in ranked:\n",
    "        if i == index:\n",
    "            continue\n",
    "        count += 1\n",
    "        print(f\"Recommendation #{count}\")\n",
    "        print(descriptions[i])\n",
    "        print(f\"Similarity: {scores[i]:.3f}\\n\")\n",
    "        if count >= k:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49adf804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def get_recommendations(article_index, num_recommendations):\n",
    "    \"\"\"Get recommendations based on article index\"\"\"\n",
    "    try:\n",
    "        article_index = int(article_index)\n",
    "        num_recommendations = int(num_recommendations)\n",
    "        \n",
    "        if article_index < 0 or article_index >= len(descriptions):\n",
    "            return \"Error: Invalid article index. Please enter a value between 0 and \" + str(len(descriptions) - 1)\n",
    "        \n",
    "        if num_recommendations < 1 or num_recommendations > 10:\n",
    "            return \"Error: Number of recommendations should be between 1 and 10\"\n",
    "        \n",
    "        query = embeddings[article_index].reshape(1, -1)\n",
    "        scores = cosine_similarity(query, embeddings)[0]\n",
    "        ranked = scores.argsort()[::-1]\n",
    "        \n",
    "        result = \"ðŸ“° **SOURCE ARTICLE:**\\n\\n\"\n",
    "        result += descriptions[article_index] + \"\\n\\n\"\n",
    "        result += \"---\\n\\n\"\n",
    "        result += \"âœ¨ **RECOMMENDATIONS:**\\n\\n\"\n",
    "        \n",
    "        count = 0\n",
    "        for i in ranked:\n",
    "            if i == article_index:\n",
    "                continue\n",
    "            count += 1\n",
    "            result += f\"**#{count}** | Similarity: {scores[i]:.3f}\\n\\n\"\n",
    "            result += descriptions[i] + \"\\n\\n---\\n\\n\"\n",
    "            if count >= num_recommendations:\n",
    "                break\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=get_recommendations,\n",
    "    inputs=[\n",
    "        gr.Slider(\n",
    "            minimum=0,\n",
    "            maximum=len(descriptions) - 1,\n",
    "            step=1,\n",
    "            label=\"Article Index\",\n",
    "            info=f\"Select an article (0-{len(descriptions) - 1})\"\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            minimum=1,\n",
    "            maximum=10,\n",
    "            step=1,\n",
    "            value=5,\n",
    "            label=\"Number of Recommendations\",\n",
    "            info=\"How many recommendations do you want?\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=gr.Markdown(label=\"Results\"),\n",
    "    title=\"ðŸ“š Content-Based Recommendation System\",\n",
    "    description=\"Find similar articles using OpenAI embeddings and cosine similarity\",\n",
    "    theme=gr.themes.Soft(),\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
